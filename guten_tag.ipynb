{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hearlvein/colab/blob/main/guten_tag.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "85e78fb2",
      "metadata": {
        "id": "85e78fb2"
      },
      "source": [
        "# ðŸª Fine-Tuning GPT-2 with LoRA for Poetic Sci-Fi/Fantasy Story Generation\n",
        "\n",
        "This notebook guides you through fine-tuning GPT-2 using Low-Rank Adaptation (LoRA) to generate poetic sci-fi/fantasy short stories. The process includes:\n",
        "- Dataset preparation from Project Gutenberg\n",
        "- Model fine-tuning with LoRA\n",
        "- Story generation based on user prompts\n",
        "\n",
        "**Note:** This notebook is designed for execution in Google Colab."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "38cb754d",
      "metadata": {
        "id": "38cb754d"
      },
      "source": [
        "## ðŸ”§ Setup and Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "4dc4a906",
      "metadata": {
        "id": "4dc4a906",
        "outputId": "42d8fc6c-42f1-4ef2-ade6-e9e485bf3274",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m32.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m313.6/313.6 kB\u001b[0m \u001b[31m29.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for httpsproxy-urllib2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "# Install necessary packages\n",
        "!pip install -q transformers datasets peft trl bitsandbytes accelerate\n",
        "!pip install -q beautifulsoup4 requests gutenbergpy"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "05b944d2",
      "metadata": {
        "id": "05b944d2"
      },
      "source": [
        "## ðŸ“š Dataset Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "ae02ca8a",
      "metadata": {
        "id": "ae02ca8a",
        "outputId": "eae0a526-346c-4b8d-87e3-9a825a6ddeba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading Gutenberg metadata cache...\n",
            "Downloading book ID 145...\n",
            "Saved book 145 to gutenberg_dataset/science_fiction/145.txt\n",
            "Downloading book ID 2160...\n",
            "Saved book 2160 to gutenberg_dataset/science_fiction/2160.txt\n",
            "Downloading book ID 1259...\n",
            "Saved book 1259 to gutenberg_dataset/science_fiction/1259.txt\n",
            "Downloading book ID 4085...\n",
            "Saved book 4085 to gutenberg_dataset/science_fiction/4085.txt\n",
            "Downloading book ID 98...\n",
            "Saved book 98 to gutenberg_dataset/science_fiction/98.txt\n",
            "Downloading book ID 2600...\n",
            "Saved book 2600 to gutenberg_dataset/science_fiction/2600.txt\n",
            "Downloading book ID 135...\n",
            "Saved book 135 to gutenberg_dataset/science_fiction/135.txt\n",
            "Downloading book ID 120...\n",
            "Saved book 120 to gutenberg_dataset/science_fiction/120.txt\n",
            "Downloading book ID 1837...\n",
            "Saved book 1837 to gutenberg_dataset/science_fiction/1837.txt\n",
            "Downloading book ID 73...\n",
            "Saved book 73 to gutenberg_dataset/science_fiction/73.txt\n",
            "Loading Gutenberg metadata cache...\n",
            "Downloading book ID 16328...\n",
            "Saved book 16328 to gutenberg_dataset/poetry/16328.txt\n",
            "Downloading book ID 1322...\n",
            "Saved book 1322 to gutenberg_dataset/poetry/1322.txt\n",
            "Downloading book ID 228...\n",
            "Saved book 228 to gutenberg_dataset/poetry/228.txt\n",
            "Downloading book ID 2490...\n",
            "Saved book 2490 to gutenberg_dataset/poetry/2490.txt\n",
            "Downloading book ID 14568...\n",
            "Saved book 14568 to gutenberg_dataset/poetry/14568.txt\n",
            "Downloading book ID 9622...\n",
            "Saved book 9622 to gutenberg_dataset/poetry/9622.txt\n",
            "Downloading book ID 3333...\n",
            "Saved book 3333 to gutenberg_dataset/poetry/3333.txt\n",
            "Downloading book ID 1321...\n",
            "Saved book 1321 to gutenberg_dataset/poetry/1321.txt\n",
            "Downloading book ID 20...\n",
            "Saved book 20 to gutenberg_dataset/poetry/20.txt\n",
            "Downloading book ID 847...\n",
            "Saved book 847 to gutenberg_dataset/poetry/847.txt\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import re\n",
        "import json\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "from gutenbergpy.textget import get_text_by_id\n",
        "from gutenbergpy.gutenbergcache import GutenbergCache\n",
        "\n",
        "\n",
        "# Define genres and corresponding Project Gutenberg bookshelf URLs\n",
        "bookshelves = {\n",
        "    'science_fiction': 'https://www.gutenberg.org/ebooks/bookshelf/41',\n",
        "    'poetry': 'https://www.gutenberg.org/ebooks/bookshelf/60',\n",
        "}\n",
        "\n",
        "# Function to extract book IDs from a Project Gutenberg bookshelf\n",
        "def get_book_ids_from_bookshelf(url, limit=10):\n",
        "    response = requests.get(url)\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "    book_links = soup.select('li.booklink a.link')\n",
        "    book_ids = []\n",
        "\n",
        "    for link in book_links:\n",
        "        href = link.get('href')\n",
        "        if href.startswith('/ebooks/'):\n",
        "            book_id = href.split('/')[-1]\n",
        "            if book_id.isdigit():\n",
        "                book_ids.append(int(book_id))\n",
        "                if len(book_ids) == limit:\n",
        "                    break\n",
        "    return book_ids\n",
        "\n",
        "# Function to download book texts given their IDs\n",
        "def download_books(book_ids, output_folder):\n",
        "    from gutenbergpy.textget import get_text_by_id\n",
        "    from gutenbergpy.gutenbergcache import GutenbergCache\n",
        "\n",
        "    os.makedirs(output_folder, exist_ok=True)\n",
        "    print(\"Loading Gutenberg metadata cache...\")\n",
        "    cache = GutenbergCache.get_cache()\n",
        "    for book_id in book_ids:\n",
        "        output_path = os.path.join(output_folder, f\"{book_id}.txt\")\n",
        "        if os.path.exists(output_path) and os.path.getsize(output_path) > 0:\n",
        "            print(f\"Book {book_id} already exists at {output_path}, skipping download.\")\n",
        "            continue\n",
        "        print(f\"Downloading book ID {book_id}...\")\n",
        "        try:\n",
        "            text_bytes = get_text_by_id(book_id)\n",
        "            text_str = text_bytes.decode('utf-8', errors='ignore')\n",
        "            with open(output_path, 'w', encoding='utf-8') as f:\n",
        "                f.write(text_str)\n",
        "            print(f\"Saved book {book_id} to {output_path}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error downloading book {book_id}: {e}\")\n",
        "\n",
        "# Utility function to download books by genre\n",
        "def download_books_to_dataset(bookshelf_url, genre, limit=10, base_folder=\"gutenberg_dataset\"):\n",
        "    output_folder = os.path.join(base_folder, genre)\n",
        "    book_ids = get_book_ids_from_bookshelf(bookshelf_url, limit=limit)\n",
        "    download_books(book_ids, output_folder=output_folder)\n",
        "\n",
        "# Download books for each genre\n",
        "for genre, url in bookshelves.items():\n",
        "    download_books_to_dataset(url, genre=genre, limit=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cc1261d4",
      "metadata": {
        "id": "cc1261d4"
      },
      "source": [
        "## ðŸ§¹ Data Cleaning and JSONL Conversion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "826ddea3",
      "metadata": {
        "id": "826ddea3",
        "outputId": "af0d91b8-0476-4ea8-825e-f6b918356604",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing science_fiction: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:00<00:00, 17.55it/s]\n",
            "Processing poetry: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:00<00:00, 80.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset written to gutenberg_dataset.jsonl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Define input directories and output file\n",
        "INPUT_DIRS = {\n",
        "    \"science_fiction\": Path(\"gutenberg_dataset/science_fiction\"),\n",
        "    \"poetry\": Path(\"gutenberg_dataset/poetry\"),\n",
        "}\n",
        "OUTPUT_FILE = Path(\"gutenberg_dataset.jsonl\")\n",
        "\n",
        "# Regex patterns to remove Project Gutenberg headers/footers\n",
        "HEADER_PATTERN = re.compile(\n",
        "    r\"\\*{3}\\s*START OF THIS PROJECT GUTENBERG EBOOK.*?\\*{3}\", re.IGNORECASE | re.DOTALL\n",
        ")\n",
        "FOOTER_PATTERN = re.compile(\n",
        "    r\"\\*{3}\\s*END OF THIS PROJECT GUTENBERG EBOOK.*\", re.IGNORECASE | re.DOTALL\n",
        ")\n",
        "\n",
        "# Function to clean Gutenberg text\n",
        "def clean_gutenberg_text(text: str) -> str:\n",
        "    text = HEADER_PATTERN.sub(\"\", text)\n",
        "    text = FOOTER_PATTERN.sub(\"\", text)\n",
        "    text = text.strip()\n",
        "    return text\n",
        "\n",
        "# Function to process and write data to JSONL\n",
        "def process_and_write_jsonl(input_dirs: dict, output_path: Path):\n",
        "    if output_path.exists() and output_path.stat().st_size > 0:\n",
        "        print(f\"{output_path} already exists and is non-empty, skipping processing.\")\n",
        "        return\n",
        "    with output_path.open(\"w\", encoding=\"utf-8\") as out_file:\n",
        "        for source_label, folder in input_dirs.items():\n",
        "            txt_files = list(folder.rglob(\"*.txt\"))\n",
        "            for txt_path in tqdm(txt_files, desc=f\"Processing {source_label}\"):\n",
        "                try:\n",
        "                    raw = txt_path.read_text(encoding=\"utf-8\", errors=\"ignore\")\n",
        "                    clean = clean_gutenberg_text(raw)\n",
        "                    if not clean:\n",
        "                        continue\n",
        "                    record = {\n",
        "                        \"source\": source_label,\n",
        "                        \"filename\": txt_path.name,\n",
        "                        \"text\": clean,\n",
        "                    }\n",
        "                    out_file.write(json.dumps(record, ensure_ascii=False) + \"\\n\")\n",
        "                except Exception as e:\n",
        "                    print(f\"Error processing {txt_path}: {e}\")\n",
        "\n",
        "# Process and write the dataset\n",
        "os.makedirs(OUTPUT_FILE.parent, exist_ok=True)\n",
        "process_and_write_jsonl(INPUT_DIRS, OUTPUT_FILE)\n",
        "print(f\"Dataset written to {OUTPUT_FILE}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f7a42369",
      "metadata": {
        "id": "f7a42369"
      },
      "source": [
        "## ðŸ§  Model Fine-Tuning with LoRA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "ceb3d2ce",
      "metadata": {
        "id": "ceb3d2ce",
        "outputId": "71385b57-fef1-43ff-96c7-2970f4b078db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283,
          "referenced_widgets": [
            "927cb5416d0a4623894b5becec63ff3c",
            "fc5ba1536ee94daa83c8d5538f41e0de",
            "c81899bf07584883ae460ba4449ec9a0",
            "056f27b35fcd45b5a7cb7b69da0451ca",
            "426e3e8965bf4018b4fcc0e28132b507",
            "1ba3aa23e48f447999d121dd2f0ac75a",
            "2253de7d8f8c48b9990800575039943e",
            "696ea7fbeba34cc78bb9573d47c50ace",
            "140a014f878447a0bc284699c02a9996",
            "448e63b12f154391b86b2d80b8dadfad",
            "02ad8180e8dd40f085b02282bdd91e91"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading dataset...\n",
            "Dataset loaded with 20 records.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/20 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "927cb5416d0a4623894b5becec63ff3c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "SFTConfig.__init__() got an unexpected keyword argument 'model_name_or_path'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-6780f6f3c289>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;31m# Create training arguments (SFTConfig wraps TrainingArguments internally)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m training_args = SFTConfig(\n\u001b[0m\u001b[1;32m     44\u001b[0m     \u001b[0moutput_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"./poetic_sci_fi_model\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0mper_device_train_batch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: SFTConfig.__init__() got an unexpected keyword argument 'model_name_or_path'"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from datasets import load_dataset, Dataset\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, TrainingArguments\n",
        "from peft import get_peft_model, LoraConfig, prepare_model_for_kbit_training\n",
        "from trl import SFTTrainer, SFTConfig\n",
        "\n",
        "# Load the dataset\n",
        "print(\"Loading dataset...\")\n",
        "with open(OUTPUT_FILE, 'r', encoding='utf-8') as f:\n",
        "    data = [json.loads(line) for line in f if line.strip()]\n",
        "dataset = Dataset.from_list(data)\n",
        "print(f\"Dataset loaded with {len(dataset)} records.\")\n",
        "\n",
        "# Load tokenizer and model\n",
        "MODEL_NAME = \"gpt2\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "# Load model with 8-bit precision\n",
        "bnb_config = BitsAndBytesConfig(load_in_8bit=True)\n",
        "model = AutoModelForCausalLM.from_pretrained(MODEL_NAME, quantization_config=bnb_config, device_map=\"auto\")\n",
        "model = prepare_model_for_kbit_training(model)\n",
        "\n",
        "# Configure LoRA\n",
        "lora_config = LoraConfig(\n",
        "    r=8,\n",
        "    lora_alpha=32,\n",
        "    target_modules=[\"c_attn\", \"c_proj\"],\n",
        "    lora_dropout=0.05,\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\"\n",
        ")\n",
        "model = get_peft_model(model, lora_config)\n",
        "\n",
        "# Tokenization function\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples[\"text\"], truncation=True, padding=\"max_length\", max_length=1024)\n",
        "\n",
        "# Tokenize the dataset\n",
        "tokenized_dataset = dataset.map(tokenize_function, batched=True, remove_columns=[\"text\", \"filename\", \"source\"])\n",
        "\n",
        "# Create training arguments (SFTConfig wraps TrainingArguments internally)\n",
        "training_args = SFTConfig(\n",
        "    output_dir=\"./poetic_sci_fi_model\",\n",
        "    per_device_train_batch_size=4,\n",
        "    num_train_epochs=3,\n",
        "    logging_steps=50,\n",
        "    save_strategy=\"epoch\",\n",
        "    fp16=True,\n",
        "    push_to_hub=False,\n",
        "    report_to=\"none\",\n",
        "    overwrite_output_dir=True,\n",
        "    model_name_or_path=MODEL_NAME,\n",
        "    tokenizer_name_or_path=MODEL_NAME  # ðŸ‘ˆ NEW: Required by latest SFTTrainer\n",
        ")\n",
        "\n",
        "# Initialize trainer (tokenizer no longer passed here)\n",
        "trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_dataset,\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "print(\"Starting training...\")\n",
        "trainer.train()\n",
        "\n",
        "# Save the model\n",
        "model_path = \"./poetic_sci_fi_model\"\n",
        "trainer.save_model(model_path)\n",
        "tokenizer.save_pretrained(model_path)\n",
        "print(f\"Model saved to {model_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1c02f4a9",
      "metadata": {
        "id": "1c02f4a9"
      },
      "source": [
        "## âœ¨ Story Generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3ffb9c25",
      "metadata": {
        "id": "3ffb9c25"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# Load the fine-tuned model\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_path)\n",
        "generator = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\n",
        "\n",
        "# Define a prompt\n",
        "prompt = \"In the twilight of the cosmos, a lone traveler discovers a hidden world where dreams manifest into reality.\"\n",
        "\n",
        "# Generate a story\n",
        "output = generator(\n",
        "    prompt,\n",
        "    max_new_tokens=1000,\n",
        "    do_sample=True,\n",
        "    temperature=0.95,\n",
        "    top_k=50,\n",
        "    top_p=0.92,\n",
        "    repetition_penalty=1.1,\n",
        "    num_return_sequences=1,\n",
        "    eos_token_id=tokenizer.eos_token_id\n",
        ")\n",
        "\n",
        "print(\"\\nGenerated Poetic Sci-Fi Story:\\n\")\n",
        "print(output[0][\"generated_text\"])"
      ]
    }
  ],
  "metadata": {
    "jupytext": {
      "cell_metadata_filter": "-all",
      "main_language": "python",
      "notebook_metadata_filter": "-all"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "927cb5416d0a4623894b5becec63ff3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fc5ba1536ee94daa83c8d5538f41e0de",
              "IPY_MODEL_c81899bf07584883ae460ba4449ec9a0",
              "IPY_MODEL_056f27b35fcd45b5a7cb7b69da0451ca"
            ],
            "layout": "IPY_MODEL_426e3e8965bf4018b4fcc0e28132b507"
          }
        },
        "fc5ba1536ee94daa83c8d5538f41e0de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1ba3aa23e48f447999d121dd2f0ac75a",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_2253de7d8f8c48b9990800575039943e",
            "value": "Map:â€‡100%"
          }
        },
        "c81899bf07584883ae460ba4449ec9a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_696ea7fbeba34cc78bb9573d47c50ace",
            "max": 20,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_140a014f878447a0bc284699c02a9996",
            "value": 20
          }
        },
        "056f27b35fcd45b5a7cb7b69da0451ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_448e63b12f154391b86b2d80b8dadfad",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_02ad8180e8dd40f085b02282bdd91e91",
            "value": "â€‡20/20â€‡[00:17&lt;00:00,â€‡â€‡1.12â€‡examples/s]"
          }
        },
        "426e3e8965bf4018b4fcc0e28132b507": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1ba3aa23e48f447999d121dd2f0ac75a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2253de7d8f8c48b9990800575039943e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "696ea7fbeba34cc78bb9573d47c50ace": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "140a014f878447a0bc284699c02a9996": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "448e63b12f154391b86b2d80b8dadfad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "02ad8180e8dd40f085b02282bdd91e91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}